{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Detection\n",
    "By Atwine Mugume\n",
    "\n",
    "In this kernel we are goin to apply `Transfer Learning`. \n",
    "\n",
    "You have been in that instance where you want to train a model but you don't have a GPU or enough RAM to help you do what you want to do. In this case you are put in a corner. \n",
    "\n",
    "Not anymore: you can use transfer learning. Transfer learning is the ability to take an already built model and use the weights of the model to train on your own data.\n",
    "\n",
    "Just imagine a company like Google, has the resources to train a model over 4 million images for maybe 3 days, over 50+ classes.\n",
    "\n",
    "With transfer learning you are able to take these models and work with them to solve your own problems.\n",
    "\n",
    "How amazing is this?  Really amazing.\n",
    "\n",
    "Let's get into it. \n",
    "\n",
    "We are going to be using a model called Resnet 50\n",
    "\n",
    "You can read the paper on Resnet: [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "##  Kaggle API\n",
    "\n",
    "In order to get this data in your environment. You will have to download it from Kaggle.com.\n",
    "\n",
    "You will need to download an authentication token, a json file which you will use in the setup process to work with their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvS6XGaXZcGA"
   },
   "outputs": [],
   "source": [
    "#!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Function:\n",
    "\n",
    "I wrote this function below to help anyone automate the process of using their data from Kaggle.\n",
    "\n",
    "What you will need:\n",
    "1- A json file got from kaggle in the same folder as your other data\n",
    "\n",
    "If you are working on colab you will have un comment out the lines that enable you to upload the json to the cloud platform.\n",
    "\n",
    "However everything is done by the function below.\n",
    "\n",
    "Just sit and watch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def kaggle_function():\n",
    "  \n",
    "  print('Please make sure you have downloaded a kaggle .jason token and its somewhere on your local machine')\n",
    "  print('\\n Let us first of all import the json token to Google Colab here')\n",
    "  \n",
    "  #first let's import the json file into the working directory\n",
    "  #import json\n",
    "  #from google.colab import files\n",
    "  #files.upload()\n",
    "  \n",
    "  \n",
    "  print('\\n Alright sit back and let me handle the rest for you')\n",
    "  \n",
    "  #now that we have imported the kaggle json file let us make the directory needed to keep the json file\n",
    "  !mkdir -p ~/.kaggle\n",
    "  \n",
    "  #let's copy the file there to the kaggle folder\n",
    "  !cp kaggle.json ~/.kaggle/\n",
    "  \n",
    "  #let us encrypt the file so that we don't get hacked\n",
    "  !chmod 600 ~/.kaggle/kaggle.json\n",
    "  \n",
    "  #now let's install kaggle packages\n",
    "  #!pip install kaggle\n",
    "  \n",
    "  print(\"Success! Here is the Kaggle Competitions List to show this works\")\n",
    "  \n",
    "  #let's do a simple listing of the files that kaggle has\n",
    "  !kaggle competitions list\n",
    "  \n",
    "  print('\\n\\nWhat you need to do now is: go to the competition whose data you need and copy the download code and paste it in the next cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call the Kaggle function then sit tight and watch it go to work!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the kaggle API is installed what is left is for you to go to kaggle.com and find the link from which you will download your data into your environment. Such as the one below.\n",
    "\n",
    "Your data will be downloaded into your environment for you to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "cFLZzRU1ZqBC",
    "outputId": "3caf0b03-7af0-4b62-de37-3308acc2806c"
   },
   "outputs": [],
   "source": [
    "#let's download the dataset\n",
    "#!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOQUpb1jZ_ws"
   },
   "source": [
    "#lets unzip the file\n",
    "import zipfile\n",
    "\n",
    "zipfilePath = (\"./chest_xray.zip\")\n",
    "zip = zipfile.ZipFile(zipfilePath)\n",
    "zip.extractall(\".\")\n",
    "zip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uHx1kz8ZCVK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import __version__\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, AveragePooling2D, GlobalAveragePooling2D, Input, Flatten, Dropout, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation Utility Functions\n",
    "\n",
    "I need to work on some visualisations for the data that I have in my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "From here onwards we work on building the model that we are going to train to classify the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnzFhjSHZCVP"
   },
   "outputs": [],
   "source": [
    "IM_WIDTH, IM_HEIGHT = 299, 299 \n",
    "NB_EPOCHS = 20\n",
    "BAT_SIZE = 32\n",
    "FC_SIZE = 1024\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzaUSqEmZCVS"
   },
   "outputs": [],
   "source": [
    "def get_nb_files(directory):\n",
    "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        return 0\n",
    "    cnt = 0\n",
    "    for r, dirs, files in os.walk(directory):\n",
    "        for dr in dirs:\n",
    "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTjRsU2MZCVV"
   },
   "outputs": [],
   "source": [
    "def setup_to_transfer_learn(model, base_model):\n",
    "    \"\"\"Freeze all layers and compile the model\"\"\"\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgbdmsclZCVX"
   },
   "outputs": [],
   "source": [
    "def add_new_last_layer(base_model, nb_classes):\n",
    "    x = base_model.output\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = AveragePooling2D((8, 8), border_mode='valid', name='avg_pool')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    predictions = Dense(2, activation='sigmoid')(x)\n",
    "    model = Model(input=base_model.input, output=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "EkRBUERsZCVa",
    "outputId": "27889528-b1c6-4334-f91f-77d25dd24b64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "## For best Val ACC found, save the model at that epoch\n",
    "filepath=\"Resnet50_weights_3.h5\"\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eiPNQXQjZCVd"
   },
   "outputs": [],
   "source": [
    "def train(epochs, output_model_file, plot = True ):\n",
    "    \"\"\"Using transfer learning \"\"\"\n",
    "    train_img = 'chest_xray/train/' \n",
    "    validation_img = 'chest_xray/val/'\n",
    "    nb_epoch = int(epochs)\n",
    "    nb_train_samples = get_nb_files(train_img)\n",
    "    nb_classes = len(glob.glob(train_img + \"/*\"))\n",
    "    # data prep\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "\t\t\ttrain_img,\n",
    "\t\t\ttarget_size=(299, 299),\n",
    "\t\t\tbatch_size=32,\n",
    "\t\t\tclass_mode='categorical'\n",
    "\t\t\t)\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "\t\t\tvalidation_img,\n",
    "\t\t\ttarget_size=(299, 299),\n",
    "\t\t\tbatch_size=32,\n",
    "\t\t\tclass_mode='categorical'\n",
    "\t\t\t)\n",
    "    if(K.image_dim_ordering() == 'th'):\n",
    "        input_tensor = Input(shape=(3, 299, 299))\n",
    "    else:\n",
    "        input_tensor = Input(shape=(299, 299, 3))\n",
    "    \n",
    "    # setup model\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    base_model = ResNet50(input_tensor = input_tensor,weights='imagenet', include_top=False) #include_top=False excludes final FC layer\n",
    "    model = add_new_last_layer(base_model, nb_classes)\n",
    "    \n",
    "    # transfer learning\n",
    "    setup_to_transfer_learn(model, base_model)\n",
    "    \n",
    "    \n",
    "    \n",
    "    history_tl = model.fit_generator(train_generator,\n",
    "                                   samples_per_epoch=320,\n",
    "                                   nb_epoch=nb_epoch,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   nb_val_samples=64,\n",
    "                                   callbacks=[lr_reduce,checkpoint]) \n",
    "    model.save(output_model_file)\n",
    "    if plot:\n",
    "        plot_training(history_tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA6YVsmYZCVf"
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.plot(epochs, acc, 'r.')\n",
    "    plt.plot(epochs, val_acc, 'r')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.savefig('accuracy.png')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'r.')\n",
    "    plt.plot(epochs, val_loss, 'r-')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "id": "gYihG3QRZCVi",
    "outputId": "d0d702a1-ad2a-4688-9a9e-1d4d387b452a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((8, 8), name=\"avg_pool\", padding=\"valid\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=<keras_pre..., callbacks=[<keras.ca..., steps_per_epoch=10, epochs=25, validation_steps=64)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 667s 67s/step - loss: 0.5126 - acc: 0.7500 - val_loss: 2.0078 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.50000, saving model to Resnet50_weights_3.h5\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 636s 64s/step - loss: 0.3396 - acc: 0.8344 - val_loss: 1.4296 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.50000\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 643s 64s/step - loss: 0.3209 - acc: 0.8313 - val_loss: 1.1648 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.50000\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 635s 63s/step - loss: 0.2761 - acc: 0.8781 - val_loss: 1.0357 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.50000\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 636s 64s/step - loss: 0.3278 - acc: 0.8281 - val_loss: 0.9624 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.50000\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 634s 63s/step - loss: 0.2933 - acc: 0.8656 - val_loss: 0.9112 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.50000\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 635s 64s/step - loss: 0.3211 - acc: 0.8406 - val_loss: 0.8737 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.50000\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 636s 64s/step - loss: 0.3296 - acc: 0.8125 - val_loss: 0.8358 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.50000\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 637s 64s/step - loss: 0.3643 - acc: 0.8000 - val_loss: 0.8297 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.50000\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 716s 72s/step - loss: 0.3143 - acc: 0.8594 - val_loss: 0.8236 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.50000\n",
      "Epoch 11/25\n",
      " 9/10 [==========================>...] - ETA: 15s - loss: 0.2951 - acc: 0.8576"
     ]
    }
   ],
   "source": [
    "train(epochs = 25, output_model_file = './resnet_new_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSlJ8VD7ZCVl"
   },
   "source": [
    "### Validation accuracy achieved ~80%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5TyqP5WZCVm"
   },
   "source": [
    "## Predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wxs7gzzdZCVn"
   },
   "outputs": [],
   "source": [
    "target_size = (299, 299) # for Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXlGIQ4aZCVp"
   },
   "outputs": [],
   "source": [
    "def predict(model, img, target_size = target_size):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.resize(img,(299,299))\n",
    "    x = np.reshape(img,[299,299,3])\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    preds = model.predict(x)\n",
    "    return preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPJEouBRZCVs"
   },
   "outputs": [],
   "source": [
    "def plot_preds(image, preds):\n",
    "    labels = (\"NORMAL\", \"PNEUMONIA\")\n",
    "    plt.barh([0, 1], preds, alpha=0.5)\n",
    "    plt.yticks([0, 1], labels)\n",
    "    plt.xlabel('Probabilities')\n",
    "    plt.xlim(0,1.01)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAThR4dBZCVu"
   },
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model = load_model('Resnet50_weights_3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2cg4a36UZCVw"
   },
   "source": [
    "### 0: Normal    1: Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4puPJB8QZCVx",
    "outputId": "2cd5ba92-ef54-446a-e2f1-c09039b2fbae"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3718: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e1a7d09ac362>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Pred 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m'test/PNEUMONIA/person48_virus_100.jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplot_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-563ad0ec9e70>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, img, target_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m299\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3718: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "# Pred 1\n",
    "img =  'chest_xray/test/PNEUMONIA/person48_virus_100.jpeg'\n",
    "preds = predict(model, img)\n",
    "plot_preds(img, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6S30V6j2ZCV0",
    "outputId": "acf1ff23-c7c5-42e5-a027-7032b7129401"
   },
   "outputs": [],
   "source": [
    "res = np.argmax(preds)\n",
    "print(res)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89DdwYSLZCV4",
    "outputId": "c5a5cac1-857e-4e91-e4de-26c4aebe7b2b"
   },
   "outputs": [],
   "source": [
    "# Pred 2\n",
    "img =  'chest_xray/test/NORMAL/IM-0105-0001.jpeg'\n",
    "preds = predict(model, img)\n",
    "plot_preds(img, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vz9at1lZCV7",
    "outputId": "ebe0f179-a380-4b8a-9fb3-41cbf69a995c"
   },
   "outputs": [],
   "source": [
    "res = np.argmax(preds)\n",
    "print(res)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aTZrIXzqZCV_",
    "outputId": "ae691068-e2a0-4fa9-9de0-92f9cde4ed6e"
   },
   "outputs": [],
   "source": [
    "# Pred 3\n",
    "img =  'chest_xray/test/PNEUMONIA/person1672_virus_2888.jpeg'\n",
    "preds = predict(model, img)\n",
    "plot_preds(img, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wrBn3zBgZCWC",
    "outputId": "ecf7ac45-4508-44b5-bd52-800961481b1f"
   },
   "outputs": [],
   "source": [
    "res = np.argmax(preds)\n",
    "print(res)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zy4QevioZCWG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pneumonia Diagnosis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
